---

Title: Interactional Epistemics (Standalone)

---
## A Permeability Criterion for Scientific and Philosophical Models

---

## Abstract

Scientific and philosophical models are sometimes treated as closed systems whose internal consistency and empirical success are taken as indicators of truth. This paper argues that such closure is best understood as a practical abstraction rather than an ontological fact. Because empirically studied systems exist within interacting environments, any model that claims to describe reality must remain open to interactions beyond its explicit scope.

I propose the **Interactional Permeability Principle**: a model that aims to describe empirical reality is epistemically legitimate only if it admits its openness to interactions from known factors, known unknowns, and unknown unknowns. Persistent mismatches between model and observation are interpreted as constraints signaling unscoped structure rather than mere noise.

This framework is grounded in a combinatorial argument: modeling requires enumerating and partitioning empirical structure, and the space of possible partitions grows explosively. Multiple inequivalent models can therefore match the same finite dataset. Permeability becomes not merely a philosophical recommendation but a structural necessity.

Interactional Epistemics shifts epistemology from the pursuit of closed, final truths to the mapping of open, interacting localities. It offers a criterion for distinguishing strategically bounded models from dogmatically closed ones.

---

## 1. Introduction

Scientific models simplify aspects of reality for the purposes of analysis. They isolate variables, ignore interactions, and operate under idealized assumptions. Such simplifications are indispensable: without them, calculation and prediction would be intractable.

A recurring epistemic error occurs when these practical simplifications are treated as ontological conclusions. Operational closure—introduced for tractability—becomes mistaken for isolation in reality.

Historically, models have often been defended despite accumulating anomalies:

- Economic models that bracket ecological constraints  
- Classical mechanics applied beyond its relativistic domain  
- Early cosmological models prior to resolving galactic rotation discrepancies  

In each case, practical limits were implicitly treated as statements about the structure of reality itself.

This paper proposes a criterion designed to prevent such dogmatic closure:

> Any model that claims to describe empirical reality must admit that it is open to interactions beyond its scope.

This is the **Interactional Permeability Principle**.

---

## 2. The Problem of Ontological Closure

### 2.1 Traditional Criteria of Scientific Legitimacy

Scientific models are typically evaluated by:

- Internal logical consistency  
- Empirical adequacy  
- Predictive success  

These criteria are necessary but not sufficient. A model may satisfy all three while still:

- Ignoring interacting domains  
- Treating idealizations as literal structure  
- Deflecting persistent mismatches as noise  

This produces **epistemic brittleness**: the model performs well within a narrow scope but fails under expanded interaction.

---

### 2.2 The Interactional Condition

Empirically studied systems are not perfectly isolated. They exist within environments in which they exchange energy, matter, or information, and are embedded within broader causal structures.

Accordingly, any model describing such a system is:

- A local approximation  
- Embedded within a larger interacting context  

This yields an epistemic condition:

> Models may be operationally closed for calculation, but should not be treated as ontologically closed in their claims about reality.

This is not a metaphysical law about the universe. It is a methodological constraint on how empirical models should be held.

---

## 3. The Combinatorial Argument for Permeability

The need for permeability is not merely historical or pragmatic. It follows from structural features of modeling itself.

### 3.1 Modeling Requires Enumeration

Empirical data is not given as pre-packaged “objects.” It consists of continuous, interacting, high-dimensional processes. To construct a model, we must:

- Select variables  
- Partition data  
- Define objects  
- Establish relations  
- Identify invariances  
- Discard information  

Each of these steps is an act of **enumeration and partitioning**.

---

### 3.2 Enumeration Is Combinatorial

Given a sufficiently large dataset, the number of possible ways to:

- Partition it,
- Group it into objects,
- Assign relations among those objects,
- Select invariances to preserve,

grows combinatorially.

Even modest sets produce astronomically many possible structural arrangements.

Therefore:

> Multiple structurally distinct models can fit the same finite dataset.

This is not epistemic pessimism; it is a combinatorial inevitability.

---

### 3.3 Underdetermination and Structural Divergence

Two theories may generate identical predictions within a scoped domain \( D \), yet differ in:

- Ontological commitments  
- Primitive objects  
- Mathematical representation  
- Compression structure  

Formally:

If  
Pred_A(D) = Pred_B(D)  

this does not imply  

Structure_A = Structure_B.

The theories may diverge outside the scoped domain:

Pred_A(D*) ≠ Pred_B(D*)

The difference lies not in current predictive success, but in future constraint trajectories.

---

### 3.4 Example: Locally Equivalent Theories

Consider two hypothetical gravitational theories that match all currently observed gravitational phenomena within a limited regime.

They may:

- Use different primitive entities  
- Encode geometry differently  
- Attribute causal structure to different mathematical objects  

Within the scoped regime, they are empirically equivalent.

But because they compress and enumerate structure differently, their extrapolations beyond that regime will differ. Their out-of-scope implications reveal their structural commitments.

Predictive equivalence within scope does not imply global equivalence.

Only interaction beyond scope distinguishes them.

---

### 3.5 Finite Agents and Incomplete Enumeration

Reality as a whole may be fully structured. However, finite modeling agents:

- Cannot enumerate all possible partitions of empirical data  
- Cannot access all scales  
- Cannot survey all interactions  

Therefore:

> No finite model can guarantee exhaustive structural capture of reality.

This does not entail relativism. It entails structural humility.

Closure is not irrational because truth is impossible.  
Closure is irrational because exhaustive enumeration is inaccessible.

Permeability follows as a rational constraint on finite agents operating within combinatorially explosive possibility spaces.

---

## 4. The Interactional Permeability Principle

### Core Criterion

A model that claims to describe empirical reality is epistemically legitimate only if:

1. It admits that it is open to interactions beyond its explicit scope.  
2. It treats excluded factors as unscoped influences rather than nonexistent ones.  
3. It interprets persistent mismatches as constraints indicating unscoped structure.

This principle applies to empirical modeling, not to purely formal systems abstracted from empirical claims.

---

### 4.1 Strategic vs. Dogmatic Closure

Because modeling requires boundaries, this framework distinguishes between two types of closure.

#### Strategic Closure

Strategic Closure is deliberate bounding for tractability while maintaining acknowledged openness.

A practitioner of Strategic Closure:

- Acknowledges the boundary  
- Expects eventual constraint pressure  
- Treats closure as computational limitation  

#### Dogmatic Closure

Dogmatic Closure occurs when practical limits are mistaken for ontological ones.

A practitioner of Dogmatic Closure:

- Denies the boundary  
- Reinterprets constraints as noise  
- Treats coherence as completeness  

The difference concerns epistemic posture, not model complexity.

---

## 5. Constraint, Clash, and Robustness

### 5.1 The Constraint Principle

A **constraint** is a stable, repeatable limitation on a model indicating unscoped interaction or structural relation.

Mismatch is not merely error.  
It is structural detection.

---

### 5.2 The Clash Principle

When models conflict, internal consistency alone does not confer authority.

Resolution depends on **relative robustness**.

**Robustness** refers to:

- Stability under parameter variation  
- Cross-domain applicability  
- Integration with independent theories  
- Empirical resilience under expanded interaction  

The more robust model acts as a constraint on the less robust one.

Strategic Closure absorbs constraint.  
Dogmatic Closure resists it.

---

## 6. From Certainty to Robust Compression

Modeling is compression.

A theory preserves invariance while discarding information. Different compressions preserve different structural commitments.

Because compression is selective and enumeration is combinatorial:

- Multiple compressions can match finite data  
- Only extended interaction reveals structural adequacy  

Science, therefore, is not the pursuit of absolute closure.

It is the iterative search for models that:

- Survive expanded interaction  
- Integrate constraint  
- Increase robustness  

Truth in the absolute sense would require exhaustive enumeration.  
Finite agents instead pursue stable compression under constraint.

---

## 7. Relation to Existing Philosophies of Science

Interactional Epistemics synthesizes:

- Popper: Falsifiability requires openness to refutation  
- Kuhn: Anomalies signal structural tension  
- Lakatos: Research programs manage protective boundaries  
- Cartwright: Laws are locally stabilized  
- Wimsatt: Heuristics are necessary for limited beings  
- Structural realism: Structure (constraint) is epistemically primary  

The combinatorial argument strengthens these insights by showing that permeability is not optional—it is structurally unavoidable.

---

## 8. Conclusion

Empirical models are local compressions of interacting structure. They arise through selective enumeration within combinatorially vast possibility spaces.

Because:

- Enumeration is combinatorial  
- Structural arrangements are underdetermined by finite data  
- Finite agents cannot exhaustively map interaction  

No model can justifiably claim ontological closure.

The Interactional Permeability Principle states:

> A model is epistemically legitimate not when it is closed, but when it admits the possibility of real structure beyond its scope.

Scientific progress becomes the disciplined expansion of scope under constraint.

**Final Thesis:**  
A model becomes dogmatic when it denies the possibility that real structure exists beyond its scoped description.